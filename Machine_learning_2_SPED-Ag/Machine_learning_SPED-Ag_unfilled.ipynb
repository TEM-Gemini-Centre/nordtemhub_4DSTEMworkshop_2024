{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5051763a-802b-4a12-ab00-076413b80216",
   "metadata": {},
   "source": [
    "## Machine learning session 2: Decomposition (unfilled version)\n",
    "**4D-STEM data analysis workshop**\n",
    "**NTNU, Trondheim, June 11, 2024** - by Tina Bergh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfefdbc-74b9-45bf-95e6-2dc5aa05d9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4753b0-0a19-49b3-9c9b-e3ff666eeb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperspy.api as hs\n",
    "import pyxem as pxm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2b486a-d096-4cbc-9cde-966cdb083b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '.\\\\'\n",
    "file = 'SPED_Ag'\n",
    "file_ending = '.hspy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d6a32-c1d4-4757-9fe3-677e05867469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ca43b-16e4-458d-86ad-89484841cc00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09449a84-fcc7-4214-9df3-6f7c3849c68a",
   "metadata": {},
   "source": [
    "# Integrate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25522b-f745-4462-92d2-197e3027311c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdf662d-ee3e-4ced-8f81-9f6a26db7f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405df0f-2a2a-4e59-81ba-89c826ab23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32a970-8bc4-4e28-bf92-8096d10ee355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123f41fb-f208-4b10-a0e9-18ef101d639f",
   "metadata": {},
   "source": [
    "## Decompose the integrated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15fbb1-1c48-4cc5-8cad-ccf931ff492e",
   "metadata": {},
   "source": [
    "Perform singular value decomposition (SVD) which factorises the data matrix into two new matrices. If the first argument is True, the data will be normalised for Poissonian noise prior to the decomposition. \n",
    "\n",
    "For more information, read the documentation here: \n",
    "- http://hyperspy.org/hyperspy-doc/current/user_guide/mva/decomposition.html\n",
    "- https://scikit-learn.org/stable/modules/decomposition.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1418a55-f9d5-4111-8491-2bd274ef0806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9edbf8-5ce8-4c86-9984-bbf73a3c877d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f20fbd-68b3-4f95-99e4-4455c25f25e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e516580-6b6d-4cc3-ae8e-ef3a54f5c11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8705916-7331-4893-890e-f2d513eb593e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9e452bb-fc8a-4ceb-9199-0274e8a8cc9f",
   "metadata": {},
   "source": [
    "Define a function that will create markers based on the reconstructed dataset. We also need the calibration and offset value for the integrated dataset (these are not the same as for the original dataset with 2D patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa3da7-51b6-4652-aaad-91a8e27ea6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = s_rad.axes_manager[2].scale\n",
    "offset = s_rad.axes_manager[2].offset\n",
    "s_rad.axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b7aa1-e0d8-4c35-9a39-f1c7c8c6d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marker_offset_signal(sig):\n",
    "    '''\n",
    "    Get the signal positions needed to define markers based on the signal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sig: numpy.ndarray\n",
    "        The signal in one navigation position, as signal.data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    xys: numpy.ndarray\n",
    "        The signal positions as [[xi,yi]] in calibrated x-units.\n",
    "    \n",
    "    '''\n",
    "    xys = np.zeros((len(sig), 2))\n",
    "    for i, sd in zip(range(len(sig)), sig):\n",
    "        xys[i] = [i*scale+offset, sd]\n",
    "    return np.array(xys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc98bf1-0df3-4fb1-bbab-548050e58874",
   "metadata": {},
   "source": [
    "Interate over the reconstructed dataset using the map function to extract marker positions for each navigation position. Create markers based on these offset positions. Then plot the integrated dataset with the reconstructed dataset as markers. Inspect how well the reconstructed dataset correspond to the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4c6117-2c59-479c-9464-41aa16a7355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = s_rad_decomp.map(get_marker_offset_signal, inplace=False, ragged=True)\n",
    "mark = hs.plot.markers.Points(offsets.data.T, color='blue') \n",
    "s_rad.plot()\n",
    "s_rad.add_marker(mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db975ad-dfca-4c2e-b9b7-21a96f62f3d5",
   "metadata": {},
   "source": [
    "## Cluster based on the decompositon results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cab335-9181-4e70-8c5e-8254e28a4d47",
   "metadata": {},
   "source": [
    "The decomposition results can further be used for clustering, i.e. finding groups of similar datapoints. The default clustering method is k-means clustering. We have to specify how many components in the decomposition results to use, and also the number of clusters that we want in the results. \n",
    "We can also use cluster_source='decomposition' if we skip the above BSS step. This will also give good results.\n",
    "\n",
    "For more information: \n",
    "- http://hyperspy.org/hyperspy-doc/current/user_guide/mva/clustering.html\n",
    "- https://scikit-learn.org/stable/modules/clustering.html\n",
    "- https://scikit-learn.org/stable/modules/clustering.html#k-means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a094fb-4c33-439b-bdb3-4ce98dd105e1",
   "metadata": {},
   "source": [
    "We want to separate the nanocrystalline region from the silver region and therefore specify two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4f2f1-a794-4132-8983-2a3c1a80ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2578d5ce-b931-4d3b-b07f-4b409a3cc69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5da5f-9149-410e-95cf-c77773f752e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e4ace-8d90-4972-808d-1378c906833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rad.plot_cluster_labels(axes_decor=\"off\");\n",
    "s_rad.plot_cluster_signals();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504e6ee0-fd10-43c9-8e1b-9f07bd1aa4ed",
   "metadata": {},
   "source": [
    "Extract the labels and use them to create a navigation mask for the nanocrystalline region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab012a8-3335-4572-b36d-07d397ad1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = s_rad.get_cluster_labels()\n",
    "nav_mask = labels.inav[1].T\n",
    "nav_mask.change_dtype('bool')\n",
    "nav_mask.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b29d9-c312-4926-86b8-71b270d489cd",
   "metadata": {},
   "source": [
    "# Decompose the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f6ba35-df22-4fd1-85c0-78c22eef1097",
   "metadata": {},
   "source": [
    "Now we will go back to working with the original dataset containing 2D patterns. \n",
    "\n",
    "By experience, this does not run if you are using the bundle with the full dataset. So, if you use the bundle, to bin the dataset more to reduce the data size before we can run it successfully. \n",
    "\n",
    "You also want to close all other processes on your PC to free as much RAM as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65fa1c-1eba-4c15-a98c-7ca4918c68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = s.rebin(scale=(2,2,2,2))\n",
    "# nav_mask = nav_mask.rebin(scale=(2,2))\n",
    "# nav_mask.change_dtype('bool')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c00a0-bfe9-44b0-bc79-c460f6ac835f",
   "metadata": {},
   "source": [
    "First, look at the maximum of the signal to inspect which regions we are interested in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512ea2b-22bd-4cce-9185-da53d1a994c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "314e6826-429f-40a1-935a-0d3950397700",
   "metadata": {},
   "source": [
    "We will create a signal mask the excludes the direct beam region, since this typically gives many components in the decomposition later. We will also exclude the region at higher scattering angles, since we have enough information contained within a smaller region. In addition, the regions to higher angles show some deviations from zone axis that would give components that we are not interested in here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700400db-39d1-4c73-ad9c-2bdb62cb8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_beam_mask0 = s.get_direct_beam_mask(radius=10.) # 5 if bundle\n",
    "direct_beam_mask1 = s.get_direct_beam_mask(radius=35.) # 17 if bundle\n",
    "direct_beam_mask1.data = ~direct_beam_mask1.data\n",
    "signal_mask = direct_beam_mask0+direct_beam_mask1\n",
    "signal_mask.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de49779-4ccb-4dcf-a529-efcb1f562697",
   "metadata": {},
   "source": [
    "### Sum Friedel pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb03368-00d1-4446-884e-52c0bfb02bd3",
   "metadata": {},
   "source": [
    "The next step is optional. It is possible to perform the decomposition on the original dataset. Since we only have zone axis patterns that obey Friedel's law, we can sum the left and right handsides of the patterns to get a smaller dataset prior to the decomposition. This will speed things up and possibly give less components associated with slight deviations from zone axis, so it can help to give decomposition results that are easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fcb33-448c-4e6e-bba5-550f58d6e45b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f8a020-9d91-40ff-a861-9ada2f4b9f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20272ef5-cf6e-4167-b312-754b25cfee2b",
   "metadata": {},
   "source": [
    "We can then rotate the left side by 180 degrees and inspect that the right and left side now look almost identical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f65fd-779f-440b-822d-49197d77fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_left_rot = s_left.rotate_diffraction(180)\n",
    "hs.plot.plot_signals([s_left_rot, s_right], norm='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1044cbb-3b32-41a3-9ecb-9ff8f604b2df",
   "metadata": {},
   "source": [
    "We can then sum the two sides and inspect the sum. The signal to noise is better, and the data size is smaller!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75e95f-ce86-4ffa-83a1-6be820e3934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rot = s_right + s_left_rot\n",
    "s_rot.plot(norm='log')\n",
    "s_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3cca9-67a7-479f-8585-d5e40e4f9294",
   "metadata": {},
   "source": [
    "We extract only the right side of the signal mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6052131-256a-4175-98eb-8b4c3847a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_mask_rot = signal_mask.isig[signal_mask.data.shape[0]/2:,:]\n",
    "signal_mask_rot.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c22eed-7a4f-4436-b310-a8ee581d3227",
   "metadata": {},
   "source": [
    "## Decompose the summed signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebad9ba-356c-4958-9c3c-95d3a19ee6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dcfeb8-24de-44a9-9ae7-cf6e3a4630a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9845330-a67e-4441-b5c4-599260c85c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40454c56-7b66-424d-b9da-71088bf1a538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9926ba4-af20-412a-8fd0-58525531b503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81dfa8-232c-4312-b075-14b31b6ec7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54163d37-405b-4757-af72-d48b251b9e3b",
   "metadata": {},
   "source": [
    "The components from SVD contain both negative and positive values, which make them hard to interpret. We can instead use an iterative matrix decomposition method called non-negative matrix factorisation (NMF) where we use the constraint that all values must be non-negative. This is consistent with the intuitive notion that you add parts together to form a whole, and it typically gives components that resembles the original signal (diffraction patterns and virtual images) to a much higher degree. It is an interative method, so we have to supply an initial guess. The default is to base the initial guess on an SVD, which by experience gives the best results. \n",
    "\n",
    "For more information: \n",
    "- http://hyperspy.org/hyperspy-doc/current/user_guide/mva/decomposition.html#non-negative-matrix-factorization-nmf\n",
    "- https://scikit-learn.org/stable/modules/decomposition.html#non-negative-matrix-factorization-nmf-or-nnmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c1e73-7348-4ca1-ac4b-4d9bd8d726cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbc75a98-b66b-4511-97a5-a0df2378ef1e",
   "metadata": {},
   "source": [
    "Extract the factors and loadings and plot them with the same navigator. The loadings resemble virtual images of the silver grains, while the factors resemble the average silver pattern within those grains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26070d0f-5961-4cc8-b929-0ca036ea5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = s_rot.get_decomposition_factors()\n",
    "loadings = s_rot.get_decomposition_loadings()\n",
    "hs.plot.plot_signals([factors, loadings], cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f3a6f-deb7-4ed7-8a55-2962416a61cb",
   "metadata": {},
   "source": [
    "## Cluster based on NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c468155-402f-4c51-8e0c-2d93fff00630",
   "metadata": {},
   "source": [
    "We cluster the NMF results to get binary masks covering each of the silver grains. We specify five clusters corresponding to the five unique silver grains. We use the same signal and navigation masks as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5064f-fb9e-4653-9023-db3f40791289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "791b785a-2ca5-4708-b901-e3a6d26a7d37",
   "metadata": {},
   "source": [
    "Plot the clustering results. First, the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1052c7-295c-42b3-9005-ff1328e4cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = s_rot.get_cluster_labels()\n",
    "hs.plot.plot_images([labels.inav[i] for i in range(5)], overlay=True, axes_decor='off', label=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954a799-2dce-4829-87d6-e4355dbeeb14",
   "metadata": {},
   "source": [
    "Then plot the mean signal within each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981ed444-a65b-4e28-bd3d-02ce6c6cf731",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_sigs = s_rot.get_cluster_signals()\n",
    "cluster_sigs.data = np.nan_to_num(cluster_sigs.data)\n",
    "hs.plot.plot_images([cluster_sigs.inav[i] for i in range(5)], overlay=True, axes_decor='off', label=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510eb208-ef15-431b-9a98-e7150285f878",
   "metadata": {},
   "source": [
    "Save the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ab9f9-2a06-4694-b73c-adc8ac187e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.save(folder+file+'_labels.hspy', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9251f5-468e-4174-a3bc-d2010a0e3a04",
   "metadata": {},
   "source": [
    "Sum the original signal within the labels. We will do this using the map function and therefore define our own function for summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c32ae-f57b-418e-a3be-1825401fa0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_signal_in_label(label):\n",
    "    return np.sum(s.data[label], axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4396c-bdcc-44e7-955f-2cdbb350772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum_signal = labels.map(sum_signal_in_label, inplace=False)\n",
    "labels_sum_signal = pxm.signals.ElectronDiffraction2D(labels_sum_signal)\n",
    "labels_sum_signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f140f9-940e-4df8-a94f-3eb371c94c27",
   "metadata": {},
   "source": [
    "We set the diffraction calibration based on the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92f81e-8fa5-4fde-8945-b328822b9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum_signal.set_diffraction_calibration(s.axes_manager[3].scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e8993-0299-48b6-88f7-a99b9b907cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum_signal.axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f954e-80d7-4c47-a6f6-a4e27f9cf8eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_sum_signal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f5157f-2e36-478f-af16-04e6406331ca",
   "metadata": {},
   "source": [
    "Save the summed signal within each cluster. We will use these as a staring point for the next session!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4c20cf-94aa-41af-89d2-5a5bf532f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sum_signal.save(folder+file+'_labels_sum_signal.hspy', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cc9f3-7245-448a-8edb-f614940c667e",
   "metadata": {},
   "source": [
    "## Perform NMF with more components\n",
    "If we inspect the dataset, we see that we have many more spots than those picked up by the NMF using only 6 components. In the overlap regions, we get double diffraction giving these extra spots. Where did they go? If a signal in your dataset is not accounting for a large protion of the variance in the whole dataset, this signal can go unnoticed in the decomposition. It is not trivial to find the best number of components for your dataset, and great care must be taken!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f40ce-a69a-46e9-b09c-e98d28e5050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "s_rot.decomposition(True, 'NMF', 20, navigation_mask=nav_mask, signal_mask=signal_mask_rot)\n",
    "tf = time()\n",
    "print('NMF done in ' + str((tf-t0)) + ' s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a95933-10db-426b-a062-3bb245f7fd1c",
   "metadata": {},
   "source": [
    "Plot the results and see if you can find the double diffraction spots now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73396cee-34f5-425e-ba03-5f05415348b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_rot_NMF20 = s_rot.get_decomposition_factors()\n",
    "loadings_rot_NMF20 = s_rot.get_decomposition_loadings()\n",
    "hs.plot.plot_signals([factors_rot_NMF20, loadings_rot_NMF20], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f847d-b24d-448b-9f73-0fdcf9029dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
